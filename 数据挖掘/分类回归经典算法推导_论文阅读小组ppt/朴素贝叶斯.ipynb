{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#朴素贝叶斯分类器\n",
    "class NBayes():\n",
    "    #设置属性\n",
    "    def __init__(self) -> None:\n",
    "        self.trainSet=0  #训练集\n",
    "        self.trainLabel=0 #训练集标签\n",
    "        self.yProba={}#先验概率容器\n",
    "        self.xyProba={}#条件概率容器\n",
    "        self.ySet={} #标记类别对应的数量\n",
    "        self.ls=1    #拉普拉斯平滑系数\n",
    "        self.n_samples=0 #训练集样本数量\n",
    "        self.n_features=0 #训练集特征数量\n",
    "    \n",
    "    #计算先验概率——每个标记的占比\n",
    "    def comPy(self,y,Ls=True):\n",
    "        Py={}\n",
    "        yi={}\n",
    "        #获取类别数\n",
    "        ySet=np.unique(y)\n",
    "        #带入拉普拉斯平滑做统计处理\n",
    "        for i in ySet:\n",
    "            Py[i]=(sum(y==i)+self.ls)/(self.n_samples+len(ySet))#Py:{y1:a,y2:b} a+b=1\n",
    "            yi[i]=sum(y==i)#yi={y1:m,y2:n} m+n=y.len()\n",
    "        self.yProba=Py\n",
    "        self.ySet=yi\n",
    "        return\n",
    "    \n",
    "    #计算条件概率\n",
    "    def comPxy(self,X,y,LS=True):\n",
    "        Pxy={}\n",
    "        for yi,yiCount in self.ySet.items():#(yi,yiCount)=》y的一个类别，这个类别占的数量\n",
    "            Pxy[yi]={}#Pxy={y1:{},y2:{}}\n",
    "            for xindex in range(self.n_features):#遍历访问特征矩阵的每一个特征Xi 非具体的值  而是特征名称\n",
    "                Pxy[yi][xindex]={}#Pxy=Pxy={y1:{X1:{},X2:{}....},y2:{}}\n",
    "                #下标为第index的特征数据\n",
    "                Xi=X[:,xindex]#获取第xindex个特征整列的数据\n",
    "                Xiset=np.unique(Xi)\n",
    "                Xicount=Xiset.size#获取这一列也就是Xi这个特征下的取值类别和类别数\n",
    "                #下标为index，且标记为yi的特征数据\n",
    "                Xiyi=X[np.nonzero(y==yi)[0],xindex]#nonzero（）用于得到数组中非零元素的位置（数组索引）\n",
    "                #Xiyi是一个数组 记录的是y=yi的条件下且位于index列的特征数据\n",
    "                for xi in Xiset:\n",
    "                    Pxy[yi][xindex][xi] = self.classifyProba(xi, Xiyi, Xicount)    #第三层是变量Xi的分类概率，离散变量 实际上就是p（XI=xi|yi）的条件概率\n",
    "        self.xyProba = Pxy\n",
    "        return        \n",
    "    #离散变量直接计算概率\n",
    "    def classifyProba(self, x, xArr, Xicount):\n",
    "        Pxy = (sum(xArr == x) + self.ls) / (xArr.size + Xicount)    #加入拉普拉斯修正的概率\n",
    "        return Pxy\n",
    "                    \n",
    "\n",
    "    #训练\n",
    "    def train(self,X,y):\n",
    "        self.n_samples,self.n_features=X.shape\n",
    "        #计算先验概率  就是不同类的y所占比例和数量\n",
    "        self.comPy(y)\n",
    "        print('P(y)计算完毕')\n",
    "        #计算条件概率\n",
    "        self.comPxy(X,y)\n",
    "        print('P(x|y)计算完毕')\n",
    "        self.trainSet=X\n",
    "        self.trainLabel=y\n",
    "        return\n",
    "    \n",
    "\n",
    "    #预测\n",
    "    def predict(self,X):\n",
    "        m,n=X.shape\n",
    "        #生成一个维度是((m,len(self.yProba))的二维数组\n",
    "        proba=np.zeros((m,len(self.yProba)))#proba=[[0,0],[0,0],....]\n",
    "        for i in range(m):\n",
    "            for idx,(yi,Py) in enumerate(self.yProba.items()):\n",
    "                #0 (0.0, 0.5263157894736842)\n",
    "                #1 (1.0, 0.47368421052631576)\n",
    "                proba_idx=Py\n",
    "                for xidx in range(n):\n",
    "                    xi=X[i,xidx]\n",
    "                    proba_idx*=self.xyProba[yi][xidx][xi]#计算的是p（yi）*(p（X1=xi|yi）*p（X2=xi|yi）*....\n",
    "                proba[i,idx]=proba_idx\n",
    "        return proba\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y)计算完毕\n",
      "P(x|y)计算完毕\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "dataSet = [\n",
    "        ['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.697, 0.460, '好瓜'],\n",
    "        ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', 0.774, 0.376, '好瓜'],\n",
    "        ['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.634, 0.264, '好瓜'],\n",
    "        ['青绿', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', 0.608, 0.318, '好瓜'],\n",
    "        ['浅白', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.556, 0.215, '好瓜'],\n",
    "        ['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 0.403, 0.237, '好瓜'],\n",
    "        ['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', 0.481, 0.149, '好瓜'],\n",
    "        ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '硬滑', 0.437, 0.211, '好瓜'],\n",
    "        ['乌黑', '稍蜷', '沉闷', '稍糊', '稍凹', '硬滑', 0.666, 0.091, '坏瓜'],\n",
    "        ['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', 0.243, 0.267, '坏瓜'],\n",
    "        ['浅白', '硬挺', '清脆', '模糊', '平坦', '硬滑', 0.245, 0.057, '坏瓜'],\n",
    "        ['浅白', '蜷缩', '浊响', '模糊', '平坦', '软粘', 0.343, 0.099, '坏瓜'],\n",
    "        ['青绿', '稍蜷', '浊响', '稍糊', '凹陷', '硬滑', 0.639, 0.161, '坏瓜'],\n",
    "        ['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', 0.657, 0.198, '坏瓜'],\n",
    "        ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 0.360, 0.370, '坏瓜'],\n",
    "        ['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', 0.593, 0.042, '坏瓜'],\n",
    "        ['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', 0.719, 0.103, '坏瓜']\n",
    "    ]\n",
    "#特征值列表\n",
    "labels = ['色泽', '根蒂', '敲击', '纹理', '脐部', '触感', '密度', '含糖率']\n",
    "dataX = np.array(dataSet)[:,:6]\n",
    "oriencode = OrdinalEncoder(categories='auto')\n",
    "oriencode.fit(dataX)\n",
    "X=oriencode.transform(dataX)\n",
    "y = np.array(dataSet)[:,8]\n",
    "y[y==\"好瓜\"]=1\n",
    "y[y==\"坏瓜\"]=0\n",
    "y=y.astype(float)\n",
    "#训练\n",
    "NB = NBayes()\n",
    "NB.train(X, y)\n",
    "Proba = NB.predict(X)\n",
    "#返回np数组中最大值的索引\n",
    "yPredict = np.argmax(Proba, axis=1)\n",
    "sum((y-yPredict)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 0.5263157894736842, 1.0: 0.47368421052631576}\n",
      "\n",
      "\n",
      "{0.0: {0: {0.0: 0.25, 1.0: 0.4166666666666667, 2.0: 0.3333333333333333}, 1: {0.0: 0.25, 1.0: 0.4166666666666667, 2.0: 0.3333333333333333}, 2: {0.0: 0.3333333333333333, 1.0: 0.4166666666666667, 2.0: 0.25}, 3: {0.0: 0.3333333333333333, 1.0: 0.25, 2.0: 0.4166666666666667}, 4: {0.0: 0.25, 1.0: 0.4166666666666667, 2.0: 0.3333333333333333}, 5: {0.0: 0.6363636363636364, 1.0: 0.36363636363636365}}, 1.0: {0: {0.0: 0.45454545454545453, 1.0: 0.18181818181818182, 2.0: 0.36363636363636365}, 1: {0.0: 0.09090909090909091, 1.0: 0.36363636363636365, 2.0: 0.5454545454545454}, 2: {0.0: 0.2727272727272727, 1.0: 0.6363636363636364, 2.0: 0.09090909090909091}, 3: {0.0: 0.09090909090909091, 1.0: 0.7272727272727273, 2.0: 0.18181818181818182}, 4: {0.0: 0.5454545454545454, 1.0: 0.09090909090909091, 2.0: 0.36363636363636365}, 5: {0.0: 0.7, 1.0: 0.3}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#打印先验概率\n",
    "print(NB.yProba)\n",
    "print('\\n')\n",
    "#打印条件概率\n",
    "print(NB.xyProba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#朴素贝叶斯——连续值处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "class Bayes(object):\n",
    "    def __init__(self,trainData):\n",
    "        self.trainData=trainData\n",
    "        # model_par以字典形式存放每一个类别的方差\n",
    "        self.model_para={}#均值和方差\n",
    "        self.yproba=0#先验概率\n",
    "\n",
    "        \n",
    "    def tarin_bayesModel(self):\n",
    "        # 将训练集按照类别进行提取\n",
    "        Py={}\n",
    "        #获取类别数\n",
    "        ySet=np.unique(pd.DataFrame(self.trainData).iloc[:,-1])\n",
    "        #带入拉普拉斯平滑做统计处理\n",
    "        for i in ySet:\n",
    "            Py[i]=(sum(pd.DataFrame(self.trainData).iloc[:,-1]==i)+1)/(len(pd.DataFrame(self.trainData).iloc[:,-1])+len(ySet))#Py:{y1:a,y2:b} a+b=1\n",
    "        self.yProba=Py\n",
    "   \n",
    "       \n",
    "        separated_class=self.separateByClass()#{0:[v1,v2,v3....],1:{v5,v7..}...}\n",
    "        # vectors是列表，包含的是每个类别对应的向量集\n",
    "        for classValue, vectors in separated_class.items():\n",
    "            #例如1，[v5,v7] vi是向量\n",
    "            # 将每一个类别的均值和方差保存在对应的键值对中\n",
    "            self.model_para[classValue] = self.summarize(vectors)#self.model_para={0:[(mean1,variance1),(mean2,variance2)...],1:[..]..}\n",
    "        return self.model_para\n",
    "    \n",
    "    # 计算均值\n",
    "    def mean(self,numbers):\n",
    "        return sum(numbers) / float(len(numbers))\n",
    " \n",
    "    # 计算方差，注意是分母是n-1，自由度\n",
    "    def stdev(self,numbers):\n",
    "        avg = self.mean(numbers)\n",
    "        variance = sum([pow(x - avg, 2) for x in numbers]) / float(len(numbers) - 1)\n",
    "        return math.sqrt(variance)\n",
    " \n",
    "    # 对每一类样本的每个特征计算均值和方差，结果保存在列表中，依次为第一维特征、第二维特征等...的均值和方差\n",
    "    def summarize(self,vectors):\n",
    "        # zip利用 * 号操作符，可以将不同元组或者列表压缩为为列表集合。用来提取每类样本下的每一维的特征集合\n",
    "        summaries = [(self.mean(attribute), self.stdev(attribute)) for attribute in zip(*vectors)]\n",
    "        #zip(*[[4.9, 3. , 1.4, 0.2],[4.7, 3.2, 1.3, 0.2]])=>[(4.9,4.7),(3,3.2)...]即attitude是这个类别下某一列特征的值的集合\n",
    "        # 将代表类别的最后一个数据删掉，只保留均值和方差\n",
    "        del summaries[-1]\n",
    "        return summaries\n",
    " \n",
    " \n",
    "    # 将训练集按照类别进行提取，以字典形式存放，Key为类别，value为列表，列表中包含的是每个类别对应的向量集\n",
    "    def separateByClass(self):\n",
    "        #字典用于存放分类后的向量集合\n",
    "        separated_class = {}\n",
    "        for i in range(len(self.trainData)):\n",
    "            vector = self.trainData[i]\n",
    "            # vector[-1]为每组数据的类别\n",
    "            if (vector[-1] not in separated_class):\n",
    "                separated_class[vector[-1]] = []\n",
    "            #     将每列数据存放在对应的类别下，列表形式\n",
    "            separated_class[vector[-1]].append(vector)\n",
    "        return separated_class\n",
    " \n",
    "    # 假定服从正态分布，对连续属性计算概率密度函数,公式参考周志华老师的西瓜书P151\n",
    "    def calProbabilityDensity(self,x, mean, stdev):\n",
    "        # x为待分类数据\n",
    "        exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "        return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    " \n",
    "    # 计算待分类数据的联合概率\n",
    "    def calClassProbabilities(self, inputVector):\n",
    "        # summaries为训练好的贝叶斯模型参数, inputVector为待分类数据(单个)\n",
    "        # probabilities用来保存待分类数据对每种类别的联合概率\n",
    "        probabilities = {}\n",
    "        # classValue为字典的key(类别) ,classSummaries为字典的vlaue(每个类别每维特征的均值和方差),列表形式\n",
    "        for classValue, classSummaries in self.model_para.items():\n",
    "            probabilities[classValue] = self.yProba[classValue]#获得p（c）\n",
    "            # len(classSummaries)表示有多少特征维度\n",
    "            for i in range(len(classSummaries)):\n",
    "                # mean, stdev分贝别表示每维特征对应的均值和方差\n",
    "                mean, stdev = classSummaries[i]\n",
    "                # 提取待分类数据的i维数据值\n",
    "                x = inputVector[i]\n",
    "                # 计算联合概率密度\n",
    "                probabilities[classValue] *= self.calProbabilityDensity(x, mean, stdev)\n",
    "        # 返回概率最大的类别\n",
    "        prediction=max(probabilities,key=probabilities.get)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类准确率 97.777778\n"
     ]
    }
   ],
   "source": [
    "# 计算分类准确率\n",
    "def calAccuracy(testData,bayes):\n",
    "    correct_nums=0\n",
    "    for i in range(len(testData)):\n",
    "        # 逐次计算每一个数据的分类类别\n",
    "        if  testData[i][-1]== bayes.calClassProbabilities(testData[i]):\n",
    "            correct_nums += 1\n",
    "    return correct_nums\n",
    " \n",
    "d=load_iris()\n",
    "train_data=pd.DataFrame(d['data'])\n",
    "train_target=pd.DataFrame(d['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_target, test_size=0.3, random_state=42)\n",
    "trainData=pd.concat([X_train,y_train],axis=1)\n",
    "bayes=Bayes(np.array(trainData))\n",
    "# model为训练之后的bayes分类器模型的概率参数\n",
    "model=bayes.tarin_bayesModel()\n",
    "testData=pd.concat([X_test,y_test],axis=1)\n",
    "correct_nums=calAccuracy(np.array(testData), bayes)\n",
    "print(\"分类准确率 %f\"%(correct_nums/len(testData) * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
